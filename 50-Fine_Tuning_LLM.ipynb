{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOOBk78/oy1FjQNkXJG4M/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmartigani/RoadMapIA/blob/main/Fine_Tuning_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBEzwidZ8dVg"
      },
      "outputs": [],
      "source": [
        "En este caso práctico, se propone al alumno la realización de instruction fine-tuning\n",
        "sobre el LLM Flan-T5-small con el objetivo de que sea capaz de\n",
        "resumir artículos de periódico en el idioma Español."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "AoyrdYZa8psx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Importamos el tokenizador\n",
        "tokenizer_FT5 = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "\n",
        "# Importamos el modelo pre-entrenado\n",
        "model_FT5 = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\", device_map=\"auto\")"
      ],
      "metadata": {
        "id": "6bnCkg8n8sqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Astrónomos detectaron una misteriosa ráfaga de ondas de radio que tardó \\\n",
        "8.000 millones de años en llegar a la Tierra. La ráfaga rápida de radio es una de \\\n",
        "las más distantes y energéticas jamás observadas. Las ráfagas rápidas de radio \\\n",
        "(FRB, por sus siglas en inglés) son intensos estallidos de ondas de radio de \\\n",
        "milisegundos de duración cuyo origen se desconoce. La primera FRB se descubrió \\\n",
        "en 2007 y, desde entonces, se han detectado cientos de estos rápidos destellos \\\n",
        "cósmicos procedentes de puntos distantes de todo el universo.\"\"\""
      ],
      "metadata": {
        "id": "62MmOWvz8sn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\"La Revolución Industrial, que tuvo lugar principalmente en el siglo XIX, \\\n",
        "fue un período de grandes cambios tecnológicos, culturales y socioeconómicos que \\\n",
        "transformó a las sociedades agrarias en sociedades industriales. Durante este tiempo, \\\n",
        "hubo un cambio masivo de mano de obra de las granjas a las fábricas. Esto se debió a \\\n",
        "la invención de nuevas máquinas que podían realizar tareas más rápido y eficientemente \\\n",
        "que los humanos o los animales. Esta transición llevó a un aumento en la producción de \\\n",
        "bienes, pero también tuvo consecuencias negativas, como la explotación \\laboral y la \\\n",
        "contaminación ambiental.\"\"\""
      ],
      "metadata": {
        "id": "s-XmCe3w8sle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\"El telescopio Hubble, lanzado al espacio en 1990, ha proporcionado imágenes \\\n",
        "impresionantes del universo y ha ayudado a los científicos a comprender mejor la cosmología.\"\"\""
      ],
      "metadata": {
        "id": "l20kVdhf8sih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = f\"Resume el siguiente articulo:\\n\\n{text}\"\n",
        "\n",
        "# Tokenizamos el prompt\n",
        "prompt_tokens = tokenizer_FT5(prompt_template, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "# Generamos los siguientes tokens\n",
        "outputs = model_FT5.generate(prompt_tokens, max_length=200)\n",
        "\n",
        "# Transformamos los tokens generados en texto\n",
        "print(tokenizer_FT5.decode(outputs[0]))"
      ],
      "metadata": {
        "id": "Dg_37_PZ8sfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "El conjunto de datos que vamos a utilizar para la realización del fine-tuning se corresponde con MLSUM.\n",
        "MLSUM es el primer conjunto de datos de resumen multilingüe a gran escala"
      ],
      "metadata": {
        "id": "PFC0tPEB8scy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"date\": \"01/01/2001\",\n",
        "    \"summary\": \"A text\",\n",
        "    \"text\": \"This is a text\",\n",
        "    \"title\": \"A sample\",\n",
        "    \"topic\": \"football\",\n",
        "    \"url\": \"https://www.google.com\"\n",
        "}"
      ],
      "metadata": {
        "id": "YcRe6Pr48sZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"mlsum\", 'es')"
      ],
      "metadata": {
        "id": "MYxrVOkP8sX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "id": "FJTVg18C8sU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos un ejemplo del subconjunto de datos de entrenamiento\n",
        "ds[\"train\"][\"text\"][10]"
      ],
      "metadata": {
        "id": "swKev_jL8sQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos el resumen correspondiente al ejemplo anterior\n",
        "ds[\"train\"][\"summary\"][10]"
      ],
      "metadata": {
        "id": "U8XoU4tk8sNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(prompt, completion)"
      ],
      "metadata": {
        "id": "jgoffj-d8sJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Debe indicarse una instrucción para que realice el modelo.\n",
        "Es habitual utilizar plantillas que proponen los desarrolladores de los LLM\n",
        "para diseñar nuestros ejemplos de entrenamiento:\n",
        "https://github.com/google-research/FLAN/blob/main/flan/v2/flan_templates_branched.py"
      ],
      "metadata": {
        "id": "_82xUpBx8sF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\"Resume el siguiente articulo:\\n\\n{text}\", \"{summary}\")"
      ],
      "metadata": {
        "id": "nJwZ4f4N8sA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\"Conversación:\\n[Usuario] ¿Cuál es la capital de Francia?\\n[Asistente] La capital de Francia es París.\\n[Usuario] ¿Y cuál es su río principal?\\n[Asistente] \", \"Su río principal es el Sena\")"
      ],
      "metadata": {
        "id": "M6XJSMw09XF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reducimos el conjunto de datos\n",
        "NUM_EJ_TRAIN = 1500\n",
        "NUM_EJ_VAL = 500\n",
        "NUM_EJ_TEST = 200\n",
        "\n",
        "# Subconjunto de entrenamiento\n",
        "ds['train'] = ds['train'].select(range(NUM_EJ_TRAIN))\n",
        "\n",
        "# Subconjunto de validación\n",
        "ds['validation'] = ds['validation'].select(range(NUM_EJ_VAL))\n",
        "\n",
        "# Subconjunto de pruebas\n",
        "ds['test'] = ds['test'].select(range(NUM_EJ_TEST))"
      ],
      "metadata": {
        "id": "LkWydzcO9XA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "id": "a9chvBxJ9W8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_dataset(ejemplo):\n",
        "  \"\"\"Procesa los ejemplos para adaptarlos a la plantilla.\"\"\"\n",
        "  return {\"prompt\": f\"Resume el siguiente articulo:\\n\\n{ejemplo['text']}\"}"
      ],
      "metadata": {
        "id": "2yEomRag9W3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds[\"train\"] = ds[\"train\"].map(parse_dataset)\n",
        "ds[\"validation\"] = ds[\"validation\"].map(parse_dataset)\n",
        "ds[\"test\"] = ds[\"test\"].map(parse_dataset)"
      ],
      "metadata": {
        "id": "yUad5Olq9Wzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "id": "yw4pq2_x9WuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds[\"train\"][\"prompt\"][10])"
      ],
      "metadata": {
        "id": "nPC-eR2J9lqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds[\"train\"][\"text\"][10])"
      ],
      "metadata": {
        "id": "cQLOaTht9llZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")"
      ],
      "metadata": {
        "id": "8wNzpWDd9lgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "# Calculamos el tamaño máximo de prompt\n",
        "prompts_tokens = concatenate_datasets([ds[\"train\"], ds[\"validation\"], ds[\"test\"]]).map(lambda x: tokenizer(x[\"prompt\"], truncation=True), batched=True) # Va a truncar en 512 que es el tamaño máximo para este modelo\n",
        "max_token_len = max([len(x) for x in prompts_tokens[\"input_ids\"]])\n",
        "print(f\"Maximo tamaño de prompt: {max_token_len}\")\n",
        "\n",
        "# Calculamos el tamaño máximo de completion\n",
        "completions_tokens = concatenate_datasets([ds[\"train\"], ds[\"validation\"], ds[\"test\"]]).map(lambda x: tokenizer(x[\"summary\"], truncation=True), batched=True)\n",
        "max_completion_len = max([len(x) for x in completions_tokens[\"input_ids\"]])\n",
        "print(f\"Maximo tamaño de completion: {max_completion_len}\")"
      ],
      "metadata": {
        "id": "L0-Eenjj9lbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padding_tokenizer(datos):\n",
        "  # Tokenizar inputs (prompts)\n",
        "  model_inputs = tokenizer(datos['prompt'], max_length=max_token_len, padding=\"max_length\", truncation=True)\n",
        "\n",
        "  # Tokenizar labels (completions)\n",
        "  model_labels = tokenizer(datos['summary'], max_length=max_completion_len, padding=\"max_length\", truncation=True)\n",
        "\n",
        "  # Sustituimos el caracter de padding de las completion por -100 para que no se tenga en cuenta en el entrenamiento\n",
        "  model_labels[\"input_ids\"] = [[(l if l != tokenizer.pad_token_id else -100) for l in label] for label in model_labels[\"input_ids\"]]\n",
        "\n",
        "  model_inputs['labels'] = model_labels[\"input_ids\"]\n",
        "\n",
        "  return model_inputs"
      ],
      "metadata": {
        "id": "kq1w05Uh9yq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_tokens = ds.map(padding_tokenizer, batched=True, remove_columns=['text', 'summary', 'topic', 'url', 'title', 'date', 'prompt'])"
      ],
      "metadata": {
        "id": "q9_nTrNO9yoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_tokens"
      ],
      "metadata": {
        "id": "H5ZXx1xF9ylR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_tokens[\"train\"][\"input_ids\"][10]"
      ],
      "metadata": {
        "id": "bjwK6CVu9yiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "# Cargamos el modelo\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")"
      ],
      "metadata": {
        "id": "0KYApo8v97sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "# Metrica de evaluación\n",
        "metric = evaluate.load(\"rouge\")\n",
        "\n",
        "# Funciona auxiliar para preprocesar el texto\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # rougeLSum espera una nueva línea después de cada frase\n",
        "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Reemplazamos -100 en las etiquetas porque no podemos decodificarlo\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Preprocesamos el texto\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    return result"
      ],
      "metadata": {
        "id": "S3cE8U3H97pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# Ignoramos los tokens relacionados con el padding durante el proceso de entrenamiento para los prompts\n",
        "label_pad_token_id = -100\n",
        "\n",
        "# Recolector de datos para el entrenamiento del modelo\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=label_pad_token_id,\n",
        "    pad_to_multiple_of=8\n",
        ")"
      ],
      "metadata": {
        "id": "5-YZpTNX97nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "REPOSITORY=\"/content/drive/MyDrive/flan-t5-small-fine-tuned\"\n",
        "\n",
        "# Definimos las opciones del entrenamiento\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    # Hiperprámetros del entrenamiento\n",
        "    output_dir=REPOSITORY,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    predict_with_generate=True,\n",
        "    fp16=False,  # Overflows with fp16\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=4,\n",
        "    # Estrategias de logging y evaluación\n",
        "    logging_dir=f\"{REPOSITORY}/logs\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=500,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "# Creamos la instancia de entrenamiento\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=ds_tokens[\"train\"],\n",
        "    eval_dataset=ds_tokens[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "E26OhFzh97kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos el tokenizador en disco para utilizarlo posteriormente\n",
        "tokenizer.save_pretrained(f\"{REPOSITORY}/tokenizer\")"
      ],
      "metadata": {
        "id": "qK9vnixe97hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciamos el entrenamiento\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "8QbGP2Dm-IFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "REPOSITORY=\"/content/drive/MyDrive/flan-t5-small-fine-tuned\"\n",
        "\n",
        "# Importamos el tokenizador\n",
        "tokenizer_FT5_FT = T5Tokenizer.from_pretrained(f\"{REPOSITORY}/tokenizer\")\n",
        "\n",
        "# Importamos el modelo con fine-tuning\n",
        "model_FT5_FT = T5ForConditionalGeneration.from_pretrained(f\"{REPOSITORY}/checkpoint-752\", device_map=\"auto\")"
      ],
      "metadata": {
        "id": "LpKM0ign-IAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Astrónomos detectaron una misteriosa ráfaga de ondas de radio que tardó \\\n",
        "8.000 millones de años en llegar a la Tierra. La ráfaga rápida de radio es una de \\\n",
        "las más distantes y energéticas jamás observadas. Las ráfagas rápidas de radio \\\n",
        "(FRB, por sus siglas en inglés) son intensos estallidos de ondas de radio de \\\n",
        "milisegundos de duración cuyo origen se desconoce. La primera FRB se descubrió \\\n",
        "en 2007 y, desde entonces, se han detectado cientos de estos rápidos destellos \\\n",
        "cósmicos procedentes de puntos distantes de todo el universo.\"\"\""
      ],
      "metadata": {
        "id": "k5PxK10A-H8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\"La Revolución Industrial, que tuvo lugar principalmente en el siglo XIX, \\\n",
        "fue un período de grandes cambios tecnológicos, culturales y socioeconómicos que \\\n",
        "transformó a las sociedades agrarias en sociedades industriales. Durante este tiempo, \\\n",
        "hubo un cambio masivo de mano de obra de las granjas a las fábricas. Esto se debió a \\\n",
        "la invención de nuevas máquinas que podían realizar tareas más rápido y eficientemente \\\n",
        "que los humanos o los animales. Esta transición llevó a un aumento en la producción de \\\n",
        "bienes, pero también tuvo consecuencias negativas, como la explotación \\laboral y la \\\n",
        "contaminación ambiental.\"\"\""
      ],
      "metadata": {
        "id": "b1luBnYz-H2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\"El telescopio Hubble, lanzado al espacio en 1990, ha proporcionado imágenes \\\n",
        "impresionantes del universo y ha ayudado a los científicos a comprender mejor la cosmología.\"\"\""
      ],
      "metadata": {
        "id": "Yo9kTtCW-HyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construimos el prompt conforme a la plantilla de fine-tuning\n",
        "prompt_template = f\"Resume el siguiente articulo:\\n\\n{text}\"\n",
        "\n",
        "# Tokenizamos el prompt\n",
        "prompt_tokens = tokenizer_FT5_FT(prompt_template, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "# Generamos los siguientes tokens\n",
        "outputs = model_FT5_FT.generate(prompt_tokens, max_length=300)\n",
        "\n",
        "# Transformamos los tokens generados en texto\n",
        "print(tokenizer_FT5_FT.decode(outputs[0]))"
      ],
      "metadata": {
        "id": "ABl9p3wu-HtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Cambiamos el modelo al modo de evaluación\n",
        "model_FT5_FT.eval()\n",
        "\n",
        "# Definir tamaño del lote\n",
        "batch_size = 8\n",
        "\n",
        "all_predictions = []\n",
        "\n",
        "# Deshabilitamos el entrenamiento y obtenemos las completions\n",
        "with torch.no_grad():\n",
        "  for i in range(0, len(ds_tokens[\"test\"][\"input_ids\"]), batch_size):\n",
        "        # Extraemos el lote actual\n",
        "        input_ids_batch = torch.tensor(ds_tokens[\"test\"][\"input_ids\"][i:i+batch_size], device='cuda:0')\n",
        "\n",
        "        # Obtenemos las predicciones del modelo\n",
        "        outputs = model_FT5_FT.generate(input_ids_batch)\n",
        "\n",
        "        # Concatenemos las predicciones\n",
        "        all_predictions.extend(outputs)\n",
        "\n",
        "# Calculamos las metricas\n",
        "labels = np.array(ds_tokens['test']['labels'])\n",
        "completions = np.array([pred.cpu().numpy() for pred in all_predictions])\n",
        "\n",
        "metrics = compute_metrics((completions, labels))\n",
        "\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "F9y9cvgT-WbI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
